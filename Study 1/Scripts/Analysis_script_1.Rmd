---
title: "Analysis_script_part1"
output: html_document
date: "2024-02-16"
---

## Load packages and data

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

load all variables

```{r}
library(tidyverse)
library(haven)
library(psych)
library(mixtools)
library(MASS)
library(nnet)
library(reshape2)
library(stargazer)
```


```{r}
df <- read.csv("C:/Users/danch/OneDrive/2 Course MS/Thesis/Data/df_full.csv", header=TRUE)[,2:263]
dfsc <- read.csv("C:/Users/danch/OneDrive/2 Course MS/Thesis/Data/df_fullsc.csv", header=TRUE)[,2:263]
```

## Preprocessing

### Recode parameters

We recode some parameters to make them more suitable for analysis, as described in Data and Measures section

save dataframe with non_respondents == 1 excluded

```{r}
dfnor <- df[df$non_respondents != 1,]
```

Introduce alternative messenger variable

```{r}
df$alt_chat_use <- ifelse(df$QA10b != 7 | df$QA10c != 7, 1, 0) # 1 if alt messenger is used at least almost never, 0 otherwise
```

Introduce civic_duty variable

```{r}
which(names(df) == "cv23o065")
which(names(df) == "cv23o073")
df$civic_duty <- rowSums(df[,219:226])
```

Introduce binary altruism variable, based on humanitarian and environmental donations

```{r}
df$altruism <- ifelse(df$org_hum_binary == "Yes" | df$org_env_binary == "Yes", 1, 0) # 1 if respondent participates in some form in a humanitarian or environmental organisations, 0 otherwise
```

Recode age to include it

```{r}
df$gebjaar_nm <- 2023 - df$gebjaar 
```

Education recode to binary

```{r}
df$oplcat_bin <- ifelse(df$oplcat %in% c(1, 2, 3), 0, 1)
```

Add Employment variable

```{r}
df$belbezig <- ifelse(df$belbezig %in% c(1, 2, 3), 1, 0)
```

Split alt_chat_use into other_messenger and secure_messenger.

```{r}
df$secure_messenger <- df$alt_chat_use
#df$alt_chat_use <- NULL
df$other_messenger <- ifelse(nchar(as.character(df$QA10f_text)) > 0, 1, 0)
```

If NA for Q11, then recode as 0

```{r}
df$QA11 <- ifelse(is.na(df$QA11), 0, df$QA11)
```

### Subsetting data

```{r}
df_non_respondents <- subset(df, non_respondents == 1)
df_screened_out <- subset(df, screened_out == 1)
df_non_compliers <- subset(df, non_compliers_actual == 1 & df$screened_out == 0, )
df_non_donators <- subset(df, non_donators == 1)
df_donators <- subset(df, donators == 1)
```

### Simulating Pseudo-population

Firstly, lets simulate proper data, as described in analytic strategy.

```{r}
set.seed(123)
### Target N = 1000
df_non_compliers_b <- df_non_compliers[sample(nrow(df_non_compliers), 1000), ]
df_non_donators_b <- df_non_donators[sample(nrow(df_non_donators), 1000, replace = TRUE), ]
df_donators_b <- df_donators[sample(nrow(df_donators), 1000, replace = TRUE), ]

# Now, non-respondents
missing_counts <- rowSums(is.na(df_non_respondents))
df_with_missing_counts <- cbind(df_non_respondents, missing_counts)
sorted_df <- df_with_missing_counts[order(missing_counts), ]
df_non_respondents_b <- sorted_df[1:600, -ncol(sorted_df)]
df_non_respondents_b <- df_non_respondents_b[sample(nrow(df_non_respondents_b), 1000, replace = TRUE), ]

### Create synthetic population

dfsynth <- rbind(df_non_respondents_b, df_non_compliers_b, df_non_donators_b, df_donators_b)
dfsynthsel <- dfsynth[dfsynth$status %in% c("non_respondents", "donators"), ]
```


##  Kruskal-Wallis tests

```{r}
### privacy concerns ###

group2 <- df_non_compliers_b$QA7
group3 <- df_non_donators_b$QA7
group4 <- df_donators_b$QA7

# Combine data into a list
data1 <- list(Group2 = group2, Group3 = group3, Group4 = group4)

# Run Kruskal-Wallis test
kruskal.test(data1) #  p-value is less than the significance level, you reject the null hypothesis and conclude that there are significant differences among the groups.

### Smartphone skill ###

group2 <- df_non_compliers_b$QA5
group3 <- df_non_donators_b$QA5
group4 <- df_donators_b$QA5

# Combine data into a list
data2 <- list(Group2 = group2, Group3 = group3, Group4 = group4)

# Run Kruskal-Wallis test
kruskal.test(data2) #  p-value is less than the significance level, you reject the null hypothesis and conclude that there are significant differences among the groups.

### WhatsApp usage ###

# Subset the vectors to match the length of the shortest vector
group2 <- df_non_compliers_b$QA10a
group3 <- df_non_donators_b$QA10a
group4 <- df_donators_b$QA10a

# Combine data into a list
data3 <- list(Group2 = group2, Group3 = group3, Group4 = group4)

# Run Kruskal-Wallis test
kruskal.test(data3) #  p-value is less than the significance level, you reject the null hypothesis and conclude that there are significant differences among the groups.

### Secure messenger ###

# Subset the vectors to match the length of the shortest vector
group2 <- df_non_compliers_b$secure_messenger
group3 <- df_non_donators_b$secure_messenger
group4 <- df_donators_b$secure_messenger

# Combine data into a list
data999 <- list(Group2 = group2, Group3 = group3, Group4 = group4)

# Run Kruskal-Wallis test
kruskal.test(data999) #  p-value is less than the significance level, you reject the null hypothesis and conclude that there are significant differences among the groups.

### Other messenger ###

# Subset the vectors to match the length of the shortest vector
group2 <- df_non_compliers_b$other_messenger
group3 <- df_non_donators_b$other_messenger
group4 <- df_donators_b$other_messenger

# Combine data into a list
data9999 <- list(Group2 = group2, Group3 = group3, Group4 = group4)

# Run Kruskal-Wallis test
kruskal.test(data9999) #  p-value is less than the significance level, you reject the null hypothesis and conclude that there are significant differences among the groups.

### Altruism ###

# Subset the vectors to match the length of the shortest vector
group1 <- df_non_respondents_b$altruism
group2 <- df_non_compliers_b$altruism
group3 <- df_non_donators_b$altruism
group4 <- df_donators_b$altruism

# Combine data into a list
data4 <- list(Group1 = group1, Group2 = group2, Group3 = group3, Group4 = group4)

# Run Kruskal-Wallis test
kruskal.test(data4) #  p-value is less than the significance level, you reject the null hypothesis and conclude that there are significant differences among the groups.

### Civic Duty ###

# Subset the vectors to match the length of the shortest vector
group1 <- df_non_respondents_b$civic_duty
group2 <- df_non_compliers_b$civic_duty
group3 <- df_non_donators_b$civic_duty
group4 <- df_donators_b$civic_duty

# Combine data into a list
data5 <- list(Group1 = group1, Group2 = group2, Group3 = group3, Group4 = group4)

# Run Kruskal-Wallis test
kruskal.test(data5) #  p-value is less than the significance level, you reject the null hypothesis and conclude that there are significant differences among the groups.

### Science Trust ###

# Subset the vectors to match the length of the shortest vector
group2 <- df_non_compliers_b$QA8b
group3 <- df_non_donators_b$QA8b
group4 <- df_donators_b$QA8b

# Combine data into a list
data6 <- list(Group2 = group2, Group3 = group3, Group4 = group4)

# Run Kruskal-Wallis test
kruskal.test(data6) #  p-value is less than the significance level, you reject the null hypothesis and conclude that there are significant differences among the groups.

### Agencies Trust ###

# Subset the vectors to match the length of the shortest vector
group2 <- df_non_compliers_b$QA8a
group3 <- df_non_donators_b$QA8a
group4 <- df_donators_b$QA8a

# Combine data into a list
data7 <- list(Group2 = group2, Group3 = group3, Group4 = group4)

# Run Kruskal-Wallis test
kruskal.test(data7) #  p-value is less than the significance level, you reject the null hypothesis and conclude that there are significant differences among the groups.

### Generalised Trust ###

# Subset the vectors to match the length of the shortest vector
group1 <- df_non_respondents_b$cp23o019
group2 <- df_non_compliers_b$cp23o019
group3 <- df_non_donators_b$cp23o019
group4 <- df_donators_b$cp23o019

# Combine data into a list
data8 <- list(Group1 = group1, Group2 = group2, Group3 = group3, Group4 = group4)

# Run Kruskal-Wallis test
kruskal.test(data8) #  p-value is less than the significance level, you reject the null hypothesis and conclude that there are significant differences among the groups.

### BIG-5 ###
### openess

# Subset the vectors to match the length of the shortest vector
group1 <- df_non_respondents_b$openess
group2 <- df_non_compliers_b$openess
group3 <- df_non_donators_b$openess
group4 <- df_donators_b$openess

# Combine data into a list
data9 <- list(Group1 = group1, Group2 = group2, Group3 = group3, Group4 = group4)

# Run Kruskal-Wallis test
kruskal.test(data9) #  p-value is less than the significance level, you reject the null hypothesis and conclude that there are significant differences among the groups.

### extrov

# Subset the vectors to match the length of the shortest vector
group1 <- df_non_respondents_b$extrov
group2 <- df_non_compliers_b$extrov
group3 <- df_non_donators_b$extrov
group4 <- df_donators_b$extrov

# Combine data into a list
data10 <- list(Group1 = group1, Group2 = group2, Group3 = group3, Group4 = group4)

# Run Kruskal-Wallis test
kruskal.test(data10)

### neurot

# Subset the vectors to match the length of the shortest vector
group1 <- df_non_respondents_b$neurot
group2 <- df_non_compliers_b$neurot
group3 <- df_non_donators_b$neurot
group4 <- df_donators_b$neurot

# Combine data into a list
data11 <- list(Group1 = group1, Group2 = group2, Group3 = group3, Group4 = group4)

# Run Kruskal-Wallis test
kruskal.test(data11)

### conscient

# Subset the vectors to match the length of the shortest vector
group1 <- df_non_respondents_b$conscient
group2 <- df_non_compliers_b$conscient
group3 <- df_non_donators_b$conscient
group4 <- df_donators_b$conscient

# Combine data into a list
data12 <- list(Group1 = group1, Group2 = group2, Group3 = group3, Group4 = group4)

# Run Kruskal-Wallis test
kruskal.test(data12) #  p-value is less than the significance level, you reject the null hypothesis and conclude that there are significant differences among the groups.

### agreab

# Subset the vectors to match the length of the shortest vector
group1 <- df_non_respondents_b$agreab
group2 <- df_non_compliers_b$agreab
group3 <- df_non_donators_b$agreab
group4 <- df_donators_b$agreab

# Combine data into a list
data13 <- list(Group1 = group1, Group2 = group2, Group3 = group3, Group4 = group4)

# Run Kruskal-Wallis test
kruskal.test(data13) #  p-value is less than the significance level, you reject the null hypothesis and conclude that there are significant differences among the groups.
```   

```{r}
### Demographics
### Gender ###

# Subset the vectors to match the length of the shortest vector
group2 <- df_non_compliers_b$geslacht
group3 <- df_non_donators_b$geslacht
group4 <- df_donators_b$geslacht
group5 <- df_non_respondents_b$geslacht

# Combine data into a list
data14 <- list(Group2 = group2, Group3 = group3, Group4 = group4, group5 = group5)

# Run Kruskal-Wallis test
kruskal.test(data14) 

### Age ###

min_length <- min(length(df_screened_out$gebjaar_nm), length(df_non_compliers$gebjaar_nm), length(df_non_donators$gebjaar_nm), length(df_donators$gebjaar_nm), length(df_non_respondents$gebjaar_nm))

# Subset the vectors to match the length of the shortest vector
group2 <- df_non_compliers_b$gebjaar_nm
group3 <- df_non_donators_b$gebjaar_nm
group4 <- df_donators_b$gebjaar_nm
group5 <- df_non_respondents_b$gebjaar_nm

# Combine data into a list
data15 <- list(Group2 = group2, Group3 = group3, Group4 = group4, group5 = group5)

# Run Kruskal-Wallis test
kruskal.test(data15) 

### Urbanisation ###

min_length <- min(length(df_screened_out$sted), length(df_non_compliers$sted), length(df_non_donators$sted), length(df_donators$sted), length(df_non_respondents$sted))

# Subset the vectors to match the length of the shortest vector
group2 <- df_non_compliers_b$sted
group3 <- df_non_donators_b$sted
group4 <- df_donators_b$sted
group5 <- df_non_respondents_b$sted

# Combine data into a list
data16 <- list(Group2 = group2, Group3 = group3, Group4 = group4, group5 = group5)

# Run Kruskal-Wallis test
kruskal.test(data16) 

### Income ###

# Subset the vectors to match the length of the shortest vector
group2 <- df_non_compliers_b$nettocat
group3 <- df_non_donators_b$nettocat
group4 <- df_donators_b$nettocat
group5 <- df_non_respondents_b$nettocat

# Combine data into a list
data17 <- list(Group2 = group2, Group3 = group3, Group4 = group4, group5 = group5)

# Run Kruskal-Wallis test
kruskal.test(data17) 

### Education ###

# Subset the vectors to match the length of the shortest vector
group2 <- df_non_compliers_b$oplcat_bin
group3 <- df_non_donators_b$oplcat_bin
group4 <- df_donators_b$oplcat_bin
group5 <- df_non_respondents_b$oplcat_bin

# Combine data into a list
data18 <- list(Group2 = group2, Group3 = group3, Group4 = group4, group5 = group5)

# Run Kruskal-Wallis test
kruskal.test(data18) 

### Employment ###

# Subset the vectors to match the length of the shortest vector
group2 <- df_non_compliers_b$belbezig
group3 <- df_non_donators_b$belbezig
group4 <- df_donators_b$belbezig
group5 <- df_non_respondents_b$belbezig

# Combine data into a list
data19 <- list(Group2 = group2, Group3 = group3, Group4 = group4, group5 = group5)

# Run Kruskal-Wallis test
kruskal.test(data19) 
```

We compare the differences between the groups of non-respondents, non-compliers, non-contributors, and donators. Both independent variables and controls are utilized in the test series.

## Check correlations

Selectively check correlations between the variables of interest. 

```{r}
#cor(na.omit(df[, c("donators", "QA7", "QA5", "QA10a", "alt_chat_use")]))
cor(na.omit(df[, c("donators", "altruism", "civic_duty", "QA8b", "QA8a", "cp23o019")]))
# more about trust
cor(na.omit(df[, c("QA8a", "QA8b", "QA8d", "QA8g", "QA8h", "cp23o019")]))
# CONSIDER stepwise regression OR LASSO to tackle multicollinearity
cor(na.omit(df[, c("donators", "openess", "extrov", "neurot", "conscient", "agreab")]))
```

## Empirical Logistic Models

Those models are presented in the Appendix, Tables 14-15

### Binary logistic regressions

For partip pred - exclude screened out.
for bias red - include them.

Consider hierachical appr - firstly knowledge, then knowledge + values, them overall.

```{r}
# no-controls
mod1_1 <- glm(donators ~ QA7 + QA5 + QA10a + alt_chat_use, 
             data = df, 
             family = binomial(link = "logit"))
summary(mod1_1)

mod1_2 <- glm(donators ~ altruism + civic_duty + QA8b +  QA8a  + cp23o019, 
             data = df, 
             family = binomial(link = "logit"))
summary(mod1_2)

mod1_3 <- glm(donators ~ openess + extrov + neurot + conscient + agreab, 
             data = df, 
             family = binomial(link = "logit"))
summary(mod1_3)

# with controls

mod2_1 <- glm(donators ~ QA7 + QA5 + QA10a + alt_chat_use + geslacht + gebjaar_nm + sted + brutocat + oplcat, 
             data = df, 
             family = binomial(link = "logit"))
summary(mod2_1)

mod2_2 <- glm(donators ~ altruism + civic_duty + QA8b +  QA8a  + cp23o019  + geslacht + gebjaar_nm + sted + brutocat + oplcat, 
             data = df, 
             family = binomial(link = "logit"))
summary(mod2_2)

mod2_3 <- glm(donators ~ openess + extrov + neurot + conscient + agreab + geslacht + gebjaar_nm + sted + brutocat + oplcat, 
             data = df, 
             family = binomial(link = "logit"))
summary(mod2_3)

# full model

mod3 <- glm(donators ~ QA7 + QA5 + QA10a + alt_chat_use + altruism + civic_duty + QA8b +  QA8a  + cp23o019 +  openess + extrov + neurot + conscient + agreab + geslacht + gebjaar_nm + sted + brutocat + oplcat, 
             data = df, 
             family = binomial(link = "logit"))
summary(mod3)
```

Now, lets do the same, but in a nested way

```{r}
md1 <- glm(donators ~ QA7 + QA5 + QA10a + alt_chat_use, 
             data = df, 
             family = binomial(link = "logit"))

md2 <- glm(donators ~ QA7 + QA5 + QA10a + alt_chat_use + altruism + civic_duty + QA8b +  QA8a  + cp23o019, 
             data = df, 
             family = binomial(link = "logit"))

md3 <- glm(donators ~ QA7 + QA5 + QA10a + alt_chat_use + altruism + civic_duty + QA8b +  QA8a  + cp23o019 + openess + extrov + neurot + conscient + agreab, 
             data = df, 
             family = binomial(link = "logit"))
summary(md3)
```


### Multinomial logistic regressions

#### No-controls models

Model 1

```{r}
mod4_1 <- multinom(status ~ QA7 + QA5 + QA10a + alt_chat_use, 
             data = df)
summary(mod4_1)
```

Now, significance

```{r}
# Get coefficient estimates and standard errors
coef <- coef(mod4_1)
std_err <- summary(mod4_1)$standard.errors

# Calculate Wald test statistic and p-values
wald_stat <- coef / std_err
p_values <- 2 * (1 - pnorm(abs(wald_stat)))
p_values
```

Model 2

```{r}
mod4_2 <- multinom(status ~ altruism + civic_duty + QA8b +  QA8a  + cp23o019, 
             data = df)
summary(mod4_2)
```

Now, significance

```{r}
# Get coefficient estimates and standard errors
coef <- coef(mod4_2)
std_err <- summary(mod4_2)$standard.errors

# Calculate Wald test statistic and p-values
wald_stat <- coef / std_err
p_values <- 2 * (1 - pnorm(abs(wald_stat)))
p_values
```

Model 3

```{r}
mod4_3 <- multinom(status ~ QA7 + QA5 + QA10a + alt_chat_use, 
             data = df)
summary(mod4_3)
```

Now, significance

```{r}
# Get coefficient estimates and standard errors
coef <- coef(mod4_3)
std_err <- summary(mod4_3)$standard.errors

# Calculate Wald test statistic and p-values
wald_stat <- coef / std_err
p_values <- 2 * (1 - pnorm(abs(wald_stat)))
p_values
```

#### Controls models

```{r}
mod5_1 <- multinom(status ~ QA7 + QA5 + QA10a + alt_chat_use + geslacht + gebjaar_nm + sted + brutocat + oplcat, 
             data = df)
summary(mod5_1)
```

Now, significance

```{r}
# Get coefficient estimates and standard errors
coef <- coef(mod5_1)
std_err <- summary(mod5_1)$standard.errors

# Calculate Wald test statistic and p-values
wald_stat <- coef / std_err
p_values <- 2 * (1 - pnorm(abs(wald_stat)))
format(p_values, scientific = FALSE)
```

Model 2

```{r}
mod5_2 <- multinom(status ~ altruism + civic_duty + QA8b +  QA8a  + cp23o019 + geslacht + gebjaar_nm + sted + brutocat + oplcat, 
             data = df)
summary(mod5_2)
```

Now, significance

```{r}
# Get coefficient estimates and standard errors
coef <- coef(mod5_2)
std_err <- summary(mod5_2)$standard.errors

# Calculate Wald test statistic and p-values
wald_stat <- coef / std_err
p_values <- 2 * (1 - pnorm(abs(wald_stat)))
format(p_values, scientific = FALSE)
```

Model 3

```{r}
mod5_3 <- multinom(status ~ QA7 + QA5 + QA10a + alt_chat_use + geslacht + gebjaar_nm + sted + brutocat + oplcat, 
             data = df)
summary(mod5_3)
```

Now, significance

```{r}
# Get coefficient estimates and standard errors
coef <- coef(mod5_3)
std_err <- summary(mod5_3)$standard.errors

# Calculate Wald test statistic and p-values
wald_stat <- coef / std_err
p_values <- 2 * (1 - pnorm(abs(wald_stat)))
format(p_values, scientific = FALSE)
```

#### Full model

```{r}
mod6_1 <- multinom(status ~ QA7 + QA5 + QA10a + alt_chat_use + altruism + civic_duty + QA8b +  QA8a  + cp23o019 +  openess + extrov + neurot + conscient + agreab + geslacht + gebjaar_nm + sted + nettocat + oplcat_bin, 
             data = df)
summary(mod6_1)
```

Significance

```{r}
# Get coefficient estimates and standard errors
coef <- coef(mod6_1)
std_err <- summary(mod6_1)$standard.errors

# Calculate Wald test statistic and p-values
wald_stat <- coef / std_err
p_values <- 2 * (1 - pnorm(abs(wald_stat)))
format(p_values, scientific = FALSE)
```

Less noisy alternative specification

```{r}
mod6_2 <- multinom(status ~ QA7 + QA5 + QA10a + altruism + QA8b + cp23o019 + extrov + geslacht + gebjaar_nm + brutocat + oplcat_bin, 
             data = df)
summary(mod6_2)
```

Significance

```{r}
# Get coefficient estimates and standard errors
coef <- coef(mod6_2)
std_err <- summary(mod6_2)$standard.errors

# Calculate Wald test statistic and p-values
wald_stat <- coef / std_err
p_values <- 2 * (1 - pnorm(abs(wald_stat)))
format(p_values, scientific = FALSE)
```

## Sample Size Effect Logistic Models

### Binary Logistic Models

```{r}
smd1 <- glm(donators ~ QA7 + QA5 + QA10a + alt_chat_use, 
             data = dfsynth, 
             family = binomial(link = "logit"))

smd2 <- glm(donators ~ altruism + civic_duty + QA8b +  QA8a  + cp23o019, 
             data = dfsynth, 
             family = binomial(link = "logit"))

smd3 <- glm(donators ~ openess + extrov + neurot + conscient + agreab, 
             data = dfsynth, 
             family = binomial(link = "logit"))


smd4 <- glm(donators ~ QA7 + QA5 + QA10a + alt_chat_use + altruism + civic_duty + QA8b +  QA8a  + cp23o019, 
             data = dfsynth, 
             family = binomial(link = "logit"))

smd5 <- glm(donators ~ QA7 + QA5 + QA10a + alt_chat_use + altruism + civic_duty + QA8b +  QA8a  + cp23o019 + openess + extrov + neurot + conscient + agreab, 
             data = dfsynth, 
             family = binomial(link = "logit"))

smd6 <- glm(donators ~ QA7 + QA5 + QA10a + alt_chat_use + altruism + civic_duty + QA8b +  QA8a  + cp23o019 +  openess + extrov + neurot + conscient + agreab + geslacht + gebjaar_nm + sted + nettocat + oplcat + belbezig, 
             data = dfsynth, 
             family = binomial(link = "logit"))

smd7 <- glm(donators ~  altruism + civic_duty  + cp23o019 +  openess + extrov + neurot + conscient + agreab + geslacht + gebjaar_nm + sted + nettocat + oplcat + belbezig, 
             data = dfsynth, 
             family = binomial(link = "logit"))
```


### Multinomial Logistic Models

```{r}
ssmmf <- multinom(status ~ QA7 + QA5 + QA10a + alt_chat_use + altruism + civic_duty + QA8b +  QA8a  + cp23o019 +  openess + extrov + neurot + conscient + agreab + geslacht + gebjaar_nm + sted + nettocat + oplcat_bin + belbezig, 
             data = dfsynth)
summary(ssmmf)
```

Significance

```{r}
# Get coefficient estimates and standard errors
coef <- coef(ssmmf)
std_err <- summary(ssmmf)$standard.errors

# Calculate Wald test statistic and p-values
wald_stat <- coef / std_err
p_values <- 2 * (1 - pnorm(abs(wald_stat)))
format(p_values, scientific = FALSE)
```

Now, attachment to multinomial model, which accounts for non-respondents.

```{r}
binmm <- glm(donators ~  altruism + civic_duty  + cp23o019 +  openess + extrov + neurot + conscient + agreab + geslacht + gebjaar_nm + sted + nettocat + oplcat + belbezig, 
             data = dfsynthsel, 
             family = binomial(link = "logit"))
summary(binmm)
```

```{r}
cor(df$QA8a, df$QA8b, use = "complete.obs")
```

## Saving Output

### Save the tables for tests

```{r}
# Perform Kruskal-Wallis tests for each dataset and store results
results <- lapply(list(data1, data2, data3, data999, data4, data5, data6, data7, data8, data9, data10, data11, data12, data13, data14, data15, data16, data17, data18, data19), kruskal.test)

# Extract test statistics and p-values from each test result
test_statistics <- sapply(results, function(x) x$statistic)
parameter <- sapply(results, function(x) x$parameter)
p_values <- sapply(results, function(x) x$p.value)
p_values_corrected <- p.adjust(p_values, method = "bonferroni")

# Combine test statistics and p-values into a data frame
results_df <- data.frame(testnum <- 1:20, Test_Statistic = test_statistics, param = parameter, P_Value = p_values, p_values_corrected = p_values_corrected)

stargazer(results_df, type = "latex", title = "Multinomial Logistic Regression Results", summary = FALSE, out = ".../Study 1/Output/testing_df.tex")
```

#### Save the tables for Emp Models

Binary models

```{r}
stargazer(mod1_1, mod1_2, mod1_3, mod2_1, mod2_2, mod2_3, mod3, type = "latex", title = "Logistic Regression Results", align = TRUE, out = ".../Study 1/Output/binarytable_emp_df.tex")
```

Multinomial models

Firstly, calculate everything

```{r}
coef <- coef(mod6_1)
coef
std_err <- summary(mod6_1)$standard.errors
std_err
wald_stat <- coef / std_err
wald_stat
p_values <- 2 * (1 - pnorm(abs(wald_stat)))
p_values
odds <- exp(coef)
odds
z_scores <- qnorm(1 - (0.05 / 2))  # For a 95% confidence interval
half_widths <- z_scores * std_err
half_widths
lower_bounds <- exp(coef - half_widths)
upper_bounds <- exp(coef + half_widths)
lower_bounds
upper_bounds
```

Now, save them as a table

```{r}
combined_table <- NULL
#combined_table <- round(cbind(coef, std_err, wald_stat, p_values, odds, lower_bounds, upper_bounds) 3)
combined_table_comp <- round(rbind(t(coef[1,]), t(std_err[1,]), t(wald_stat[1,]), t(p_values[1,]), t(odds[1,]), t(lower_bounds[1,]), t(upper_bounds[1,])), 3)
combined_table_comp <- t(combined_table_comp)
combined_table_comp

combined_table_con <- round(rbind(t(coef[2,]), t(std_err[2,]), t(wald_stat[2,]), t(p_values[2,]), t(odds[2,]), t(lower_bounds[2,]), t(upper_bounds[2,])), 3)
combined_table_con <- t(combined_table_con)
combined_table_con

combined_table_scr <- round(rbind(t(coef[3,]), t(std_err[3,]), t(wald_stat[3,]), t(p_values[3,]), t(odds[3,]), t(lower_bounds[3,]), t(upper_bounds[3,])), 3)
combined_table_scr <- t(combined_table_scr)
combined_table_scr

combined_table <- rbind(combined_table_comp, combined_table_con, combined_table_scr)

```

Add 2 naming columns

```{r}
Group <- c(rep("Non-Compliers", times = 20), rep("Non-Contributors", times = 20), rep("Screened-Out", times = 20))
Parameter <- rep(c("(Intercept)", "Privacy Concerns", "Smartphone Skill", "Whatsapp Usage", "Other Messenger", "Altruism", "Civic Duty", "Trust in Science", "Trust in Agencies", "Generalized Trust", "Openness", "Extroversion", "Neuroticism", "Conscientiousness", "Agreeableness", "Gender", "Age", "Urbanisation", "Income", "Education"), times = 2)
combined_table <- cbind(Group, Parameter, combined_table)
rownames(combined_table) <- NULL
combined_table
```

Save result

```{r}
stargazer(combined_table, type = "latex", title = "Multinomial Logistic Regression Results", summary = FALSE, out = ".../Study 1/Output/multinom_emp_df.tex")
```

#### Save the tables for Size Eff Models

Binary models

```{r}
stargazer(smd1, smd2, smd4, smd5, smd6, smd7, type = "latex", title = "Logistic Regression Results", align = TRUE, out = ".../Study 1/Output/binarytable_df.tex")
```

Multinomial models

Firstly, calculate everything

```{r}
coef <- coef(ssmmf)
coef
std_err <- summary(ssmmf)$standard.errors
std_err
wald_stat <- coef / std_err
wald_stat
p_values <- 2 * (1 - pnorm(abs(wald_stat)))
p_values
odds <- exp(coef)
odds
z_scores <- qnorm(1 - (0.05 / 2))  # For a 95% confidence interval
half_widths <- z_scores * std_err
half_widths
lower_bounds <- exp(coef - half_widths)
upper_bounds <- exp(coef + half_widths)
lower_bounds
upper_bounds
```

Now, save them as a table

```{r}
combined_table <- NULL
#combined_table <- round(cbind(coef, std_err, wald_stat, p_values, odds, lower_bounds, upper_bounds) 3)
combined_table_comp <- round(rbind(t(coef[1,]), t(std_err[1,]), t(wald_stat[1,]), t(p_values[1,]), t(odds[1,]), t(lower_bounds[1,]), t(upper_bounds[1,])), 3)
combined_table_comp <- t(combined_table_comp)
combined_table_comp

combined_table_con <- round(rbind(t(coef[2,]), t(std_err[2,]), t(wald_stat[2,]), t(p_values[2,]), t(odds[2,]), t(lower_bounds[2,]), t(upper_bounds[2,])), 3)
combined_table_con <- t(combined_table_con)
combined_table_con

combined_table <- rbind(combined_table_comp, combined_table_con)

```

Add 2 naming columns

```{r}
Group <- c(rep("Non-Compliers", times = 21), rep("Non-Contributors", times = 21))
Parameter <- rep(c("(Intercept)", "Privacy Concerns", "Smartphone Skill", "Whatsapp Usage", "Other Messenger", "Altruism", "Civic Duty", "Trust in Science", "Trust in Agencies", "Generalized Trust", "Openness", "Extroversion", "Neuroticism", "Conscientiousness", "Agreeableness", "Gender", "Age", "Urbanisation", "Income", "Education", "Employment"), times = 2)
combined_table <- cbind(Group, Parameter, combined_table)
rownames(combined_table) <- NULL
combined_table
```

Save result

```{r}
stargazer(combined_table, type = "latex", title = "Multinomial Logistic Regression Results", summary = FALSE, out = ".../Study 1/Output/multinom_df.tex")
```

Now, lets save non-respondents part

```{r}
coef <- coef(binmm)
coef
std_err <- summary(binmm)$coefficients[, "Std. Error"]
std_err
wald_stat <- coef / std_err
wald_stat
p_values <- 2 * (1 - pnorm(abs(wald_stat)))
p_values
odds <- exp(coef)
odds
z_scores <- qnorm(1 - (0.05 / 2))  # For a 95% confidence interval
z_scores
half_widths <- z_scores * std_err
half_widths
lower_bounds <- exp(coef - half_widths)
upper_bounds <- exp(coef + half_widths)
lower_bounds
upper_bounds
```

Now, save them as a table

```{r}
combined_table <- NULL
combined_table <- round(cbind(coef, std_err, wald_stat, p_values, odds, lower_bounds, upper_bounds), 3)
combined_table
```

Add 2 naming columns

```{r}
Group <- c(rep("Non-Respondents", times = 15))
Parameter <- c("(Intercept)", "Altruism", "Civic Duty", "Generalized Trust", "Openness", "Extroversion", "Neuroticism", "Conscientiousness", "Agreeableness", "Gender", "Age", "Urbanisation", "Income", "Education", "Employment")
combined_table <- cbind(Group, Parameter, combined_table)
rownames(combined_table) <- NULL
combined_table
```

Save result

```{r}
stargazer(combined_table, type = "latex", title = "Multinomial Logistic Regression Results", summary = FALSE, out = ".../Study 1/Output/multinom_nonresp_df.tex")
```

#### Save the data

We also save it as our recoding was updated

```{r}
write.csv(df, ".../Study 1/Data/df_an1.csv")
```
